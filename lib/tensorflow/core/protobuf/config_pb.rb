# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow/core/protobuf/config.proto

require 'google/protobuf'

require 'tensorflow/core/framework/cost_graph_pb'
require 'tensorflow/core/framework/graph_pb'
require 'tensorflow/core/framework/step_stats_pb'
require 'tensorflow/core/protobuf/cluster_pb'
require 'tensorflow/core/protobuf/debug_pb'
require 'tensorflow/core/protobuf/rewriter_config_pb'
Google::Protobuf::DescriptorPool.generated_pool.build do
  add_file("tensorflow/core/protobuf/config.proto", :syntax => :proto3) do
    add_message "tensorflow.GPUOptions" do
      optional :per_process_gpu_memory_fraction, :double, 1
      optional :allow_growth, :bool, 4
      optional :allocator_type, :string, 2
      optional :deferred_deletion_bytes, :int64, 3
      optional :visible_device_list, :string, 5
      optional :polling_active_delay_usecs, :int32, 6
      optional :polling_inactive_delay_msecs, :int32, 7
      optional :force_gpu_compatible, :bool, 8
      optional :experimental, :message, 9, "tensorflow.GPUOptions.Experimental"
    end
    add_message "tensorflow.GPUOptions.Experimental" do
      repeated :virtual_devices, :message, 1, "tensorflow.GPUOptions.Experimental.VirtualDevices"
      optional :use_unified_memory, :bool, 2
      optional :num_dev_to_dev_copy_streams, :int32, 3
      optional :collective_ring_order, :string, 4
      optional :timestamped_allocator, :bool, 5
      optional :kernel_tracker_max_interval, :int32, 7
      optional :kernel_tracker_max_bytes, :int32, 8
      optional :kernel_tracker_max_pending, :int32, 9
    end
    add_message "tensorflow.GPUOptions.Experimental.VirtualDevices" do
      repeated :memory_limit_mb, :float, 1
    end
    add_message "tensorflow.OptimizerOptions" do
      optional :do_common_subexpression_elimination, :bool, 1
      optional :do_constant_folding, :bool, 2
      optional :max_folded_constant_in_bytes, :int64, 6
      optional :do_function_inlining, :bool, 4
      optional :opt_level, :enum, 3, "tensorflow.OptimizerOptions.Level"
      optional :global_jit_level, :enum, 5, "tensorflow.OptimizerOptions.GlobalJitLevel"
    end
    add_enum "tensorflow.OptimizerOptions.Level" do
      value :L1, 0
      value :L0, -1
    end
    add_enum "tensorflow.OptimizerOptions.GlobalJitLevel" do
      value :DEFAULT, 0
      value :OFF, -1
      value :ON_1, 1
      value :ON_2, 2
    end
    add_message "tensorflow.GraphOptions" do
      optional :enable_recv_scheduling, :bool, 2
      optional :optimizer_options, :message, 3, "tensorflow.OptimizerOptions"
      optional :build_cost_model, :int64, 4
      optional :build_cost_model_after, :int64, 9
      optional :infer_shapes, :bool, 5
      optional :place_pruned_graph, :bool, 6
      optional :enable_bfloat16_sendrecv, :bool, 7
      optional :timeline_step, :int32, 8
      optional :rewrite_options, :message, 10, "tensorflow.RewriterConfig"
    end
    add_message "tensorflow.ThreadPoolOptionProto" do
      optional :num_threads, :int32, 1
      optional :global_name, :string, 2
    end
    add_message "tensorflow.RPCOptions" do
      optional :use_rpc_for_inprocess_master, :bool, 1
      optional :compression_algorithm, :string, 2
      optional :compression_level, :int32, 3
      optional :cache_rpc_response, :bool, 4
      optional :disable_session_connection_sharing, :bool, 5
    end
    add_message "tensorflow.SessionMetadata" do
      optional :name, :string, 1
      optional :version, :int64, 2
    end
    add_message "tensorflow.ConfigProto" do
      map :device_count, :string, :int32, 1
      optional :intra_op_parallelism_threads, :int32, 2
      optional :inter_op_parallelism_threads, :int32, 5
      optional :use_per_session_threads, :bool, 9
      repeated :session_inter_op_thread_pool, :message, 12, "tensorflow.ThreadPoolOptionProto"
      optional :placement_period, :int32, 3
      repeated :device_filters, :string, 4
      optional :gpu_options, :message, 6, "tensorflow.GPUOptions"
      optional :allow_soft_placement, :bool, 7
      optional :log_device_placement, :bool, 8
      optional :graph_options, :message, 10, "tensorflow.GraphOptions"
      optional :operation_timeout_in_ms, :int64, 11
      optional :rpc_options, :message, 13, "tensorflow.RPCOptions"
      optional :cluster_def, :message, 14, "tensorflow.ClusterDef"
      optional :isolate_session_state, :bool, 15
      optional :experimental, :message, 16, "tensorflow.ConfigProto.Experimental"
    end
    add_message "tensorflow.ConfigProto.Experimental" do
      optional :collective_group_leader, :string, 1
      optional :executor_type, :string, 3
      optional :recv_buf_max_chunk, :int32, 4
      optional :use_numa_affinity, :bool, 5
      optional :collective_deterministic_sequential_execution, :bool, 6
      optional :collective_nccl, :bool, 7
      optional :share_session_state_in_clusterspec_propagation, :bool, 8
      optional :disable_thread_spinning, :bool, 9
      optional :share_cluster_devices_in_session, :bool, 10
      optional :session_metadata, :message, 11, "tensorflow.SessionMetadata"
      optional :optimize_for_static_graph, :bool, 12
    end
    add_message "tensorflow.RunOptions" do
      optional :trace_level, :enum, 1, "tensorflow.RunOptions.TraceLevel"
      optional :timeout_in_ms, :int64, 2
      optional :inter_op_thread_pool, :int32, 3
      optional :output_partition_graphs, :bool, 5
      optional :debug_options, :message, 6, "tensorflow.DebugOptions"
      optional :report_tensor_allocations_upon_oom, :bool, 7
      optional :experimental, :message, 8, "tensorflow.RunOptions.Experimental"
    end
    add_message "tensorflow.RunOptions.Experimental" do
      optional :collective_graph_key, :int64, 1
      optional :use_run_handler_pool, :bool, 2
    end
    add_enum "tensorflow.RunOptions.TraceLevel" do
      value :NO_TRACE, 0
      value :SOFTWARE_TRACE, 1
      value :HARDWARE_TRACE, 2
      value :FULL_TRACE, 3
    end
    add_message "tensorflow.RunMetadata" do
      optional :step_stats, :message, 1, "tensorflow.StepStats"
      optional :cost_graph, :message, 2, "tensorflow.CostGraphDef"
      repeated :partition_graphs, :message, 3, "tensorflow.GraphDef"
      repeated :function_graphs, :message, 4, "tensorflow.RunMetadata.FunctionGraphs"
    end
    add_message "tensorflow.RunMetadata.FunctionGraphs" do
      repeated :partition_graphs, :message, 1, "tensorflow.GraphDef"
      optional :pre_optimization_graph, :message, 2, "tensorflow.GraphDef"
      optional :post_optimization_graph, :message, 3, "tensorflow.GraphDef"
    end
    add_message "tensorflow.TensorConnection" do
      optional :from_tensor, :string, 1
      optional :to_tensor, :string, 2
    end
    add_message "tensorflow.CallableOptions" do
      repeated :feed, :string, 1
      repeated :fetch, :string, 2
      repeated :target, :string, 3
      optional :run_options, :message, 4, "tensorflow.RunOptions"
      repeated :tensor_connection, :message, 5, "tensorflow.TensorConnection"
      map :feed_devices, :string, :string, 6
      map :fetch_devices, :string, :string, 7
      optional :fetch_skip_sync, :bool, 8
    end
  end
end

module Tensorflow
  GPUOptions = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GPUOptions").msgclass
  GPUOptions::Experimental = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GPUOptions.Experimental").msgclass
  GPUOptions::Experimental::VirtualDevices = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GPUOptions.Experimental.VirtualDevices").msgclass
  OptimizerOptions = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions").msgclass
  OptimizerOptions::Level = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions.Level").enummodule
  OptimizerOptions::GlobalJitLevel = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions.GlobalJitLevel").enummodule
  GraphOptions = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GraphOptions").msgclass
  ThreadPoolOptionProto = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ThreadPoolOptionProto").msgclass
  RPCOptions = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RPCOptions").msgclass
  SessionMetadata = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.SessionMetadata").msgclass
  ConfigProto = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ConfigProto").msgclass
  ConfigProto::Experimental = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ConfigProto.Experimental").msgclass
  RunOptions = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions").msgclass
  RunOptions::Experimental = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions.Experimental").msgclass
  RunOptions::TraceLevel = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions.TraceLevel").enummodule
  RunMetadata = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunMetadata").msgclass
  RunMetadata::FunctionGraphs = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunMetadata.FunctionGraphs").msgclass
  TensorConnection = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.TensorConnection").msgclass
  CallableOptions = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.CallableOptions").msgclass
end
